
Improved single state disambiguation worker method.

StageII: in get_edgelist_from_hashes_file, pruning the edgelist
periodically is now optional.

We can load identity pair partitions from a precomputed file now,
or recompute.

New graph partitioning algorithm implemented for partitioning
the identity pairs graph: Partitioner.py

The parallelization process in StageII is now more efficient:
Child processes are initialized once, the big fixed data 
are loaded once per child, and then blocks of data are sent to 
each child process as they finish the previous block. Idle times
eliminated, more efficient memory management.

This is accomplished through a "distribute" method and a data
generator. Now, the child processes receive a "pipe" through
which they keep receiving successive data chunks.

VerdictAuthority upgraded: the case of no middle names treated
separately.

Bootstrap method has data filenames abstracted. Other upgrades.
The case of no middle name is also added to the results-processing.

validate-national: very short names dropped. Single process search
also enabled.

config.py: variables for filenames of S2 acceptance coordinates
derived from bootstrapping.
MySQL table name for linked_identities table.

init.py: tokenization process now accepts keyword arguments.

Database.py: function to split the graph of reachable identities
into consistenct non-overlapping subgraphs in order to resolve
middlename conflicts. Currently using a spinglass algorithm which
occasionally doesn't converge. Look into a more stable implementation.

FecRetriever: re-encode occupation and employer fields after 
retrieving from DB. Otherwise, in some cases errors will occur
in string processing later on.

get_compound_identity: find all linked identities and generate a
concatenated identity string we call the compound identity.

Middle name conflict resolution methods added to IdentityManager.

Table management and export functions for linked identities table.

Method to fetch dict of linked identitis.

Person.py: in Person comparison, if names match but middle names
are different, don't simply reject; report the result for later
processing.

Record.py: in employer comparison, check if multi-token strings
are the same modulo a permutation of tokens.
Name comparison upgraded.

Tokenizer: new class TokenizerName which works just like Tokenizer
but only tokenizes the NAME field.

utils.py: new function to check if two employer strings are the same
modulo token permutation.
A number of list chunkifying functions and generators.
