'''
This module defines global variables used uniformly by various scripts.

@var data_path: the root path of the data tree structure.
@var dict_paths: a dict of various sub-directories of the data directory.
@var tokendata_file_template: template for fully qualified tokendata file. Takes two template parameters for state and Tokenizer class name.

@var vectors_file_template: This file contains a pickled dictionary \{r.id: vector for r in list_of_records\}.
@var hashes_file_template: This file contains the LSH hashes dictionary \{r.id: hash for r in list_of_records\}.
@var MySQL_tablename_all_records: Name of the table containing all records with addresses. This table is the concatenation of all <state>_combined tables.
@var log_filename: name of the log file.
'''

import os

# Global data path.
data_path = os.path.expanduser('~/data/FEC-test/')


src_path = os.path.join(os.path.dirname(__file__), '')


dict_paths = {
    "data_path": data_path,
    "data_path_vectors" :  data_path + "vectors/",
    "data_path_hashes" : data_path + "hashes/",
    "data_path_tokendata" : data_path + "tokendata/",
    "data_path_normalized_attributes" : data_path + "normalized_atrributes/",
    "data_path_affiliations_employer" : data_path + "affiliations/employer/",
    "data_path_affiliations_occupation" : data_path + "affiliations/occupation/",
    "data_path_match_buffers" : data_path + "match_buffers/",
    "data_path_near_misses" : data_path + "near_misses/",
    "data_path_candidate_pairs" : data_path + "candidate_pairs/",
    "data_path_identities": data_path + "identities/",
    "data_path_exports": data_path + "exports/",
    "tmp_path": data_path + "tmp/"
}

# Make sure the data paths exist
for url, directory in dict_paths.iteritems():
    if not os.path.exists(directory):
        os.makedirs(directory)


tokendata_file_template = dict_paths["data_path_tokendata"] + "%s-%s-tokendata.pickle"


# This file contains a pickled dictionary
# {r.id: vector for r in list_of_records}
vectors_file_template = dict_paths["data_path_vectors"] + "%s-%s-vectors.pickle"


# This file contains the LSH hashes dictionary
# {r.id: hash for r in list_of_records}
hashes_file_template = dict_paths["data_path_hashes"] + "%s-%s-hashes.pickle"


# File containing a dictionary of the normalized attributes
# of the records: {r.id: {attr_name:attr_value}}
normalized_attributes_file_template = dict_paths["data_path_normalized_attributes"] + "%s-normalized_attributes.pickle"


# File containing the edge list of related records
match_buffer_file_template = dict_paths["data_path_match_buffers"] + "%s-match_buffer.txt"


# File containing the results of all pairwise record comparisons
comparisons_file_template = dict_paths["data_path_near_misses"] + "%s-record_comparisons.json.txt"


# File with each line a json object documenting a near miss pair of records.
near_misses_file_template = dict_paths["data_path_near_misses"] + "%s-near_misses.json.txt"

# File containing the pairs of records found by hashes.get_edgelist_from_hashes_file()
# These are pairs that are candidates for comparison as judged from the hashes.
candidate_pairs_file_template = dict_paths["data_path_candidate_pairs"] + "%s-candidate_pairs.txt"

# file containing a subset of the edges in candidate_pairs_file_template. These partitions
# are generated by stage2.partition_records() and are meant to be loaded by child processes
# to be used for disambiguation.
candidate_pairs_partitioned_file_template = dict_paths["data_path_candidate_pairs"] + "%s-candidate_pairs_partition-%d.txt"


# Affiliation graph file name templates
affiliation_employer_file_template = dict_paths["data_path_affiliations_employer"] + "%s-employer_graph.gml"
affiliation_occupation_file_template = dict_paths["data_path_affiliations_occupation"] + "%s-occupation_graph.gml"


# Post-stage1 affiliation graph file name templates
affiliation_poststage1_employer_file_template = dict_paths["data_path_affiliations_employer"] + "%s-poststage1_employer_graph.gml"
affiliation_poststage1_occupation_file_template = dict_paths["data_path_affiliations_occupation"] + "%s-poststage1_occupation_graph.gml"

# Name of the table containing all records with addresses.
# This table is the concatenation of all <state>_combined tables
MySQL_tablename_all_records = 'usa_combined' 



# log file name
log_filename = data_path + "messages.log"

# String template for log messages.
# The three strings are datetime, msg_type and message
log_message_template = "[%s] (%s):\t%s\n"


# file containing all discovered related identities. Each
# line starts with a target identity and all other fields are
# related identities
related_identities_template = dict_paths['data_path_identities'] + "%s-related-identities.csv"


# file containing all discovered linked identities. Each
# line starts with a target identity and all other fields are
# linked identities
linked_identities_template = dict_paths['data_path_identities'] + "%s-linked-identities.csv"


# CSV file containin all records with an additional "identity" column as well
csv_exported_state_template = dict_paths['data_path_exports'] + "%s.csv"

